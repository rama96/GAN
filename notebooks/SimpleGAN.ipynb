{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zcQb5pwYyjy5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader  \n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  \n",
        "  def __init__(self, img_dim):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Linear(img_dim , 128),\n",
        "        nn.LeakyReLU(0.1) , # Slope of 0.1 , leaky relu performs better in GANs\n",
        "        nn.Linear(128 , 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.disc(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self , z_dim , img_dim):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "      nn.Linear(z_dim , 256),\n",
        "        nn.LeakyReLU(0.1) , # Slope of 0.1 , leaky relu performs better in GANs\n",
        "        nn.Linear(256 , img_dim),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.gen(x)\n"
      ],
      "metadata": {
        "id": "Cl3JOQoUDprf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Goes under config.py \n",
        "\n",
        "\n",
        "# Hyperparamas\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device : \" , device)\n",
        "lr = 3e-4\n",
        "z_dim = 64 # 128 , 256 \n",
        "img_dim = 28*28*1 # 784\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "\n",
        "# defining variables\n",
        "disc = Discriminator(img_dim).to(device)\n",
        "gen = Generator(z_dim , img_dim).to(device)\n",
        "fixed_noise = torch.randn((batch_size,z_dim)).to(device)\n",
        "\n",
        "# transforms \n",
        "import torchvision.transforms as transforms\n",
        "transforms = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,),(0.5,))\n",
        "      ]\n",
        ")\n",
        "\n",
        "# datasets \n",
        "dataset = datasets.MNIST(root = \"dataset/\" , transform = transforms , download = True)\n",
        "loader = DataLoader(dataset , batch_size = batch_size , shuffle = True) \n",
        "\n",
        "# optimizers \n",
        "optim_disc = optim.Adam(disc.parameters() , lr = lr)\n",
        "optim_gen = optim.Adam(gen.parameters() , lr = lr)\n",
        "\n",
        "# Loss Fn\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Tensorboard\n",
        "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
        "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
        "step = 0 \n"
      ],
      "metadata": {
        "id": "0g14ALRAD0AH",
        "outputId": "0c321a02-6e1b-407b-820b-afeb91339c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device :  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "mWDm5D8oreHN",
        "outputId": "2cfc395d-b1a1-4f6c-feda-7306a10f598c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/runs/GAN_MNIST/"
      ],
      "metadata": {
        "id": "sJjwDPcArZuZ",
        "outputId": "0285d840-4e16-4db5-b1f1-5bc98c73e832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6009, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "RcH8got3oaop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!tensorboard dev upload --logdir \"/content/runs/GAN_MNIST/fake/events.out.tfevents.1672666248.408f0282d59e.267.0\"--one_shot"
      ],
      "metadata": {
        "id": "O9jWzSUilVEP",
        "outputId": "cafe7d9f-1ab3-4b69-ec53-c6c0748c5bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload started and will continue reading any new data as it's added to the logdir.\n",
            "\n",
            "To stop uploading, press Ctrl-C.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/vcxxsNSBS521nBMn9s4MTg/\n",
            "\n",
            "\u001b[1m[2023-01-02T13:42:38]\u001b[0m Started scanning logdir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx , (real , _) in enumerate(loader):\n",
        "    \n",
        "    real = real.view(-1,784).to(device) # resizing images\n",
        "    batch_size = real.shape[0]\n",
        "\n",
        "    # Discriminator training : max : log(D(real)) + log(1-D(G(z)))\n",
        "    \n",
        "    noise = torch.randn(batch_size,z_dim).to(device)\n",
        "    fake = gen(noise)\n",
        "    disc_real = disc(real).view(-1)\n",
        "    disc_fake = disc(fake).view(-1)\n",
        "\n",
        "    lossD_real = criterion(disc_real , torch.ones_like(disc_real))\n",
        "    lossD_fake = criterion(disc_fake , torch.zeros_like(disc_fake))\n",
        "\n",
        "    lossD = (lossD_real + lossD_fake)/2\n",
        "\n",
        "    disc.zero_grad()\n",
        "    lossD.backward(retain_graph=True) # clears the gradients from cache\n",
        "    optim_disc.step()\n",
        "\n",
        "    # Generator training : min log(1-D(G(z))) -> max log(D(G(z)))\n",
        "    \n",
        "    output = disc(fake).view(-1)\n",
        "    lossG = criterion(output , torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    lossG.backward() # don't need to retain since it's not needed anymore\n",
        "    optim_gen.step()\n",
        "\n",
        "\n",
        "    # Tensorboard things : \n",
        "    if batch_idx == 0 :\n",
        "      print(f\"\"\"{epoch}/{num_epochs} completed \n",
        "            Loss D : {lossD} , lossG : {lossG} \"\"\")\n",
        "\n",
        "      with torch.no_grad():\n",
        "        fake = gen(fixed_noise).reshape(-1,1,28,28)\n",
        "        data = real.reshape(-1,1,28,28)\n",
        "\n",
        "        img_fake_grid = torchvision.utils.make_grid(fake,normalize = True)\n",
        "        img_real_grid = torchvision.utils.make_grid(real,normalize = True)\n",
        "\n",
        "        writer_fake.add_image(\"MNIST Fake images \" , img_fake_grid , global_step = step)\n",
        "        writer_real.add_image(\"MNIST Real images \" , img_real_grid , global_step = step)\n",
        "\n",
        "        step+=1\n"
      ],
      "metadata": {
        "id": "9ciwJ40QD0Zi",
        "outputId": "93f1d10f-c229-40c2-cdfc-e9cf06462ffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/5 completed \n",
            "            Loss D : 0.6914538145065308 , lossG : 0.7370061278343201 \n",
            "1/5 completed \n",
            "            Loss D : 0.3003813922405243 , lossG : 1.6012623310089111 \n",
            "2/5 completed \n",
            "            Loss D : 0.48966288566589355 , lossG : 1.3795697689056396 \n",
            "3/5 completed \n",
            "            Loss D : 0.5448020696640015 , lossG : 0.9958481788635254 \n",
            "4/5 completed \n",
            "            Loss D : 0.6209837794303894 , lossG : 0.7911437153816223 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "uvLgE2MiSL0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "plt.figure(figsize = (20,20))\n",
        "plt.imshow(img_real_grid.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "59ylhgvCeMb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torchvision.transforms.ToPILImage()(img_real_grid)\n",
        "img.show()"
      ],
      "metadata": {
        "id": "rsh0rnFlg1E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AeloxDiVhXD-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}